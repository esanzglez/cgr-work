{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syosset Park PUMS Data Analysis\n",
    "\n",
    "CGR was asked to do an analysis of the number of school children likely to be added to a community due to a housing development.  We used the 2011-15 ACS data in order to estimate the impact.\n",
    "\n",
    "# Import the Data\n",
    "We have downloaded and extracted the 2011-15 PUMS data from zip files found at https://www2.census.gov/programs-surveys/acs/data/pums/2015/5-Year/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>insp</th>\n",
       "      <th>RT</th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>DIVISION</th>\n",
       "      <th>PUMA00</th>\n",
       "      <th>PUMA10</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ST</th>\n",
       "      <th>ADJHSG</th>\n",
       "      <th>ADJINC</th>\n",
       "      <th>WGTP</th>\n",
       "      <th>NP</th>\n",
       "      <th>TYPE</th>\n",
       "      <th>ACR</th>\n",
       "      <th>AGS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>2011000000003</td>\n",
       "      <td>2</td>\n",
       "      <td>2602</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1053874</td>\n",
       "      <td>1073094</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>2011000000017</td>\n",
       "      <td>2</td>\n",
       "      <td>4309</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1053874</td>\n",
       "      <td>1073094</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>2011000000023</td>\n",
       "      <td>2</td>\n",
       "      <td>3502</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1053874</td>\n",
       "      <td>1073094</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2011000000057</td>\n",
       "      <td>2</td>\n",
       "      <td>803</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1053874</td>\n",
       "      <td>1073094</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>700.0</td>\n",
       "      <td>H</td>\n",
       "      <td>2011000000063</td>\n",
       "      <td>2</td>\n",
       "      <td>4110</td>\n",
       "      <td>-9</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>1053874</td>\n",
       "      <td>1073094</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    insp RT       SERIALNO  DIVISION  PUMA00  PUMA10  REGION  ST   ADJHSG  \\\n",
       "0    NaN  H  2011000000003         2    2602      -9       1  36  1053874   \n",
       "1    NaN  H  2011000000017         2    4309      -9       1  36  1053874   \n",
       "2    NaN  H  2011000000023         2    3502      -9       1  36  1053874   \n",
       "3  500.0  H  2011000000057         2     803      -9       1  36  1053874   \n",
       "4  700.0  H  2011000000063         2    4110      -9       1  36  1053874   \n",
       "\n",
       "    ADJINC  WGTP  NP  TYPE  ACR  AGS  \n",
       "0  1073094     8   1     1  NaN  NaN  \n",
       "1  1073094    16   1     1  NaN  NaN  \n",
       "2  1073094     0   1     2  NaN  NaN  \n",
       "3  1073094    11   4     1  2.0  1.0  \n",
       "4  1073094    28   1     1  NaN  NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in the housing data\n",
    "df_h = pd.read_csv('ss15hny.csv', low_memory=False)\n",
    "# Present a sample of the data\n",
    "df_h.iloc[:,:15].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Python3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (107,108) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RT</th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>SPORDER</th>\n",
       "      <th>PUMA00</th>\n",
       "      <th>PUMA10</th>\n",
       "      <th>ST</th>\n",
       "      <th>ADJINC</th>\n",
       "      <th>PWGTP</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>CITWP05</th>\n",
       "      <th>CITWP12</th>\n",
       "      <th>COW</th>\n",
       "      <th>DDRS</th>\n",
       "      <th>DEAR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P</td>\n",
       "      <td>2011000000003</td>\n",
       "      <td>1</td>\n",
       "      <td>2602</td>\n",
       "      <td>-9</td>\n",
       "      <td>36</td>\n",
       "      <td>1073094</td>\n",
       "      <td>8</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P</td>\n",
       "      <td>2011000000017</td>\n",
       "      <td>1</td>\n",
       "      <td>4309</td>\n",
       "      <td>-9</td>\n",
       "      <td>36</td>\n",
       "      <td>1073094</td>\n",
       "      <td>17</td>\n",
       "      <td>69</td>\n",
       "      <td>4</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P</td>\n",
       "      <td>2011000000023</td>\n",
       "      <td>1</td>\n",
       "      <td>3502</td>\n",
       "      <td>-9</td>\n",
       "      <td>36</td>\n",
       "      <td>1073094</td>\n",
       "      <td>13</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>P</td>\n",
       "      <td>2011000000057</td>\n",
       "      <td>1</td>\n",
       "      <td>803</td>\n",
       "      <td>-9</td>\n",
       "      <td>36</td>\n",
       "      <td>1073094</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>P</td>\n",
       "      <td>2011000000057</td>\n",
       "      <td>2</td>\n",
       "      <td>803</td>\n",
       "      <td>-9</td>\n",
       "      <td>36</td>\n",
       "      <td>1073094</td>\n",
       "      <td>8</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  RT       SERIALNO  SPORDER  PUMA00  PUMA10  ST   ADJINC  PWGTP  AGEP  CIT  \\\n",
       "0  P  2011000000003        1    2602      -9  36  1073094      8    70    1   \n",
       "1  P  2011000000017        1    4309      -9  36  1073094     17    69    4   \n",
       "2  P  2011000000023        1    3502      -9  36  1073094     13    81    1   \n",
       "3  P  2011000000057        1     803      -9  36  1073094     11    46    1   \n",
       "4  P  2011000000057        2     803      -9  36  1073094      8    47    1   \n",
       "\n",
       "   CITWP05  CITWP12  COW  DDRS  DEAR  \n",
       "0      NaN      NaN  NaN   2.0     2  \n",
       "1   1995.0     -9.0  1.0   2.0     1  \n",
       "2      NaN      NaN  NaN   2.0     2  \n",
       "3      NaN      NaN  4.0   2.0     2  \n",
       "4      NaN      NaN  6.0   2.0     2  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the person data\n",
    "df_p = pd.read_csv('ss15pny.csv')\n",
    "# Present a sample of the data\n",
    "df_p.iloc[:,:15].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However in an effort to conserve computer resources we are only going to keep a subset of all the varriables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SERIALNO</th>\n",
       "      <th>AGEP</th>\n",
       "      <th>PUMA00</th>\n",
       "      <th>PUMA10</th>\n",
       "      <th>PWGTP</th>\n",
       "      <th>PWGTP1</th>\n",
       "      <th>PWGTP2</th>\n",
       "      <th>PWGTP3</th>\n",
       "      <th>PWGTP4</th>\n",
       "      <th>PWGTP5</th>\n",
       "      <th>PWGTP6</th>\n",
       "      <th>PWGTP7</th>\n",
       "      <th>PWGTP8</th>\n",
       "      <th>PWGTP9</th>\n",
       "      <th>PWGTP10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011000000003</td>\n",
       "      <td>70</td>\n",
       "      <td>2602</td>\n",
       "      <td>-9</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011000000017</td>\n",
       "      <td>69</td>\n",
       "      <td>4309</td>\n",
       "      <td>-9</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>34</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011000000023</td>\n",
       "      <td>81</td>\n",
       "      <td>3502</td>\n",
       "      <td>-9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011000000057</td>\n",
       "      <td>46</td>\n",
       "      <td>803</td>\n",
       "      <td>-9</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011000000057</td>\n",
       "      <td>47</td>\n",
       "      <td>803</td>\n",
       "      <td>-9</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        SERIALNO  AGEP  PUMA00  PUMA10  PWGTP  PWGTP1  PWGTP2  PWGTP3  PWGTP4  \\\n",
       "0  2011000000003    70    2602      -9      8       7       2      12       8   \n",
       "1  2011000000017    69    4309      -9     17       5      24      10      24   \n",
       "2  2011000000023    81    3502      -9     13       2       2      12      12   \n",
       "3  2011000000057    46     803      -9     11      10       3       3      18   \n",
       "4  2011000000057    47     803      -9      8       8       2       2      13   \n",
       "\n",
       "   PWGTP5  PWGTP6  PWGTP7  PWGTP8  PWGTP9  PWGTP10  \n",
       "0       2       3       8       9       7        8  \n",
       "1      34      13      22      17      35        4  \n",
       "2      13       2      23       2      13       23  \n",
       "3       3      10      11      16      20       20  \n",
       "4       3       6      10      10      14       15  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These are the people variables we want to keep \n",
    "p_vars = ['SERIALNO', 'AGEP', 'PUMA00', 'PUMA10', 'PWGTP', 'PWGTP1', 'PWGTP2',\n",
    "          'PWGTP3', 'PWGTP4', 'PWGTP5', 'PWGTP6', 'PWGTP7', 'PWGTP8', 'PWGTP9',\n",
    "          'PWGTP10', 'PWGTP11', 'PWGTP12', 'PWGTP13', 'PWGTP14', 'PWGTP15',\n",
    "          'PWGTP16', 'PWGTP17', 'PWGTP18', 'PWGTP19', 'PWGTP20', 'PWGTP21',\n",
    "          'PWGTP22', 'PWGTP23', 'PWGTP24', 'PWGTP25', 'PWGTP26', 'PWGTP27',\n",
    "          'PWGTP28', 'PWGTP29', 'PWGTP30', 'PWGTP31', 'PWGTP32', 'PWGTP33',\n",
    "          'PWGTP34', 'PWGTP35', 'PWGTP36', 'PWGTP37', 'PWGTP38', 'PWGTP39',\n",
    "          'PWGTP40', 'PWGTP41', 'PWGTP42', 'PWGTP43', 'PWGTP44', 'PWGTP45',\n",
    "          'PWGTP46', 'PWGTP47', 'PWGTP48', 'PWGTP49', 'PWGTP50', 'PWGTP51',\n",
    "          'PWGTP52', 'PWGTP53', 'PWGTP54', 'PWGTP55', 'PWGTP56', 'PWGTP57',\n",
    "          'PWGTP58', 'PWGTP59', 'PWGTP60', 'PWGTP61', 'PWGTP62', 'PWGTP63',\n",
    "          'PWGTP64', 'PWGTP65', 'PWGTP66', 'PWGTP67', 'PWGTP68', 'PWGTP69',\n",
    "          'PWGTP70', 'PWGTP71', 'PWGTP72', 'PWGTP73', 'PWGTP74', 'PWGTP75',\n",
    "          'PWGTP76', 'PWGTP77', 'PWGTP78', 'PWGTP79', 'PWGTP80']\n",
    "# Subset the data frame\n",
    "df_p = df_p[p_vars]\n",
    "# Present the data again\n",
    "df_p.iloc[:,:15].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Method/Function\n",
    "When working with PUMS data the individual must filter the data based on the criterias of interest and sum up the weight in order to produce a point estimate.  The https://www2.census.gov/programs-surveys/acs/tech_docs/pums/ACS2011_2015_PUMS_README.pdf explains how to estimate the standard error and margin of error of the point estimate.  We will create one function that will take the Pandas data frame and calculate all three measures using a specified weight.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_estimates_and_errors(df, weight):\n",
    "    \"\"\"Calculates the estimate, standard error and margin of error of PUMS data\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): the pandas data frame of PUMS data.\n",
    "        weight (str): the weighting column name (WGTP or PWGTP).\n",
    "    Returns:\n",
    "        estimate (int): The point estimate.\n",
    "        se (int): The standard error of the estimate.\n",
    "        moe (int): The margin of error of the estimate.\n",
    "    \"\"\"\n",
    "    # Translate the weight into standard error weights \n",
    "    # i.e. 'WGPT' to ['WGTP1', ..., 'WGTP80']\n",
    "    se_weights = [weight+str(i) for i in range(1,81)]\n",
    "    # Calculate the point estimate\n",
    "    estimate = df[[weight]].sum()[weight]\n",
    "    # Calculate the standard error \n",
    "    se = ((4/80)*((df[se_weights].sum() - estimate)**2).sum())**0.5\n",
    "    # Calculate the margin of error\n",
    "    moe = 1.645 * se\n",
    "    # Convert to integers\n",
    "    estimate = int(estimate)\n",
    "    se = int(round(se,0))\n",
    "    moe = int(round(moe,0))\n",
    "    # Return the values\n",
    "    return estimate, se, moe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify the Data & Method/Function\n",
    "In order to verify our process we will first do some calculations and compare them against the values generated for NYS.  We used the PUMS estimates provided by the Census Bureau (https://www2.census.gov/programs-surveys/acs/tech_docs/pums/estimates/) and custom tabulations using Data Ferrett (https://dataferrett.census.gov/) as the basis of comparison.\n",
    "\n",
    "## PUMS Estimates\n",
    "### Total Population\n",
    "Let's see if the function defined above an duplicate the results in the PUMS estimates.  If the function is working properly the following should produce:\n",
    "\n",
    "Estimate: 19,673,174<br/>\n",
    "Standard Error: 0<br/>\n",
    "Margin of Error: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 19673174\n",
      "Standard Error: 0\n",
      "Margin of Error: 0\n"
     ]
    }
   ],
   "source": [
    "estimate, se, moe = get_estimates_and_errors(df_p, 'PWGTP')\n",
    "print('Estimate: '+str(estimate))\n",
    "print('Standard Error: '+str(se))\n",
    "print('Margin of Error: '+str(moe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Owner occupied units (TEN in 1,2)\n",
    "Now turning our focus to the housing data let's check if it produces the following:\n",
    "\n",
    "Estimate: 3,877,343<br/>\n",
    "Standard Error: 10,932<br/>\n",
    "Margin of Error: 17,983"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 3877343\n",
      "Standard Error: 10932\n",
      "Margin of Error: 17983\n"
     ]
    }
   ],
   "source": [
    "tenure_filter = np.logical_or(df_h.TEN == 1, df_h.TEN == 2)\n",
    "estimate, se, moe = get_estimates_and_errors(df_h[tenure_filter], 'WGTP')\n",
    "print('Estimate: '+str(estimate))\n",
    "print('Standard Error: '+str(se))\n",
    "print('Margin of Error: '+str(moe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vacant units (VACS has value)\n",
    "We'll check a second variable against the PUMS estimates.  If it is working it should return the following:\n",
    "\n",
    "Estimate: 909,441<br/>\n",
    "Standard Error: 7,185<br/>\n",
    "Margin of Error: 11,820"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate: 909441\n",
      "Standard Error: 7185\n",
      "Margin of Error: 11820\n"
     ]
    }
   ],
   "source": [
    "vacancy_filter = np.logical_not(np.isnan(df_h.VACS))\n",
    "estimate, se, moe = get_estimates_and_errors(df_h[vacancy_filter], 'WGTP')\n",
    "print('Estimate: '+str(estimate))\n",
    "print('Standard Error: '+str(se))\n",
    "print('Margin of Error: '+str(moe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ferrett Estimates\n",
    "Having successfully duplicated the published estimates we will move on to some more complicated estimates that we produced using data ferrett.\n",
    "### Number of Bedrooms\n",
    "We will be producing estimates based on the number of bedrooms so let's see if we can reproduce what Data Ferrett produced.  Here are the counts by the number of bedrooms:\n",
    "\n",
    "    0 = 364,738\n",
    "    1 = 1,608,898\n",
    "    2 = 2,188,920\n",
    "    3 = 2,570,555\n",
    "    4 = 1,086,802\n",
    "    5 = 255,888\n",
    "    6 = 14,041\n",
    "    7 = 0\n",
    "    8 = 62,118\n",
    "    9 = 19,765\n",
    "    N/A (GQ) = 0\n",
    "    \n",
    "We will recode these variables and will create a 6+ category, which value should be 95,924.  Data Ferrett currently does not (as far as I am aware) produce standard errors or the margin of error.  But since we have proven the methodology using the published PUMS estimates we can be sure that what it generates will be accurate.\n",
    "\n",
    "Let's recode the number of bedrooms variable.  From previous exploratory analysis I know that the values of the number of bedrooms range from 0 to 9.  The results may be in a different sort order than presented above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate of 1 Bedroom units: 1608898 +/- 10703\n",
      "Estimate of 2 Bedrooms units: 2188920 +/- 10909\n",
      "Estimate of 3 Bedrooms units: 2570555 +/- 11081\n",
      "Estimate of 4 Bedrooms units: 1086802 +/- 7778\n",
      "Estimate of 5 Bedrooms units: 255888 +/- 3839\n",
      "Estimate of 6+ Bedrooms units: 95924 +/- 2420\n",
      "Estimate of N/A (GQ) units: 0 +/- 0\n",
      "Estimate of Studio units: 364738 +/- 6594\n"
     ]
    }
   ],
   "source": [
    "def recode_BDSP(val):\n",
    "    \"\"\"Recodes the number of bedrooms (BDSP) PUMS variable\n",
    "\n",
    "    Args:\n",
    "        val (mixed): the value to be recoded.\n",
    "    Returns:\n",
    "        recoded_val (str): The new categorical variable.\n",
    "    \"\"\"\n",
    "    # This is the mapping of values to the recoded value\n",
    "    code = {0:'Studio', 1:'1 Bedroom', 2:'2 Bedrooms', 3:'3 Bedrooms', 4:'4 Bedrooms', 5:'5 Bedrooms', \n",
    "            6:'6+ Bedrooms',  7:'6+ Bedrooms', 8:'6+ Bedrooms', 9:'6+ Bedrooms'}\n",
    "    # Get the recoded value and return it\n",
    "    if val not in code:\n",
    "        recoded_val = 'N/A (GQ)'\n",
    "    else:\n",
    "        recoded_val = code[val]\n",
    "    return recoded_val\n",
    "\n",
    "# Recode the number of bedrooms\n",
    "df_h['n_bedrooms'] = df_h.BDSP.apply(recode_BDSP, 0)\n",
    "\n",
    "# Produce estimates for each number\n",
    "ns_bedrooms = df_h.n_bedrooms.unique()\n",
    "# Sort the list\n",
    "ns_bedrooms.sort()\n",
    "# Step through the list item by item\n",
    "for n_bedrooms in ns_bedrooms:\n",
    "    # Create a filter for the data frame\n",
    "    df_filter = df_h.n_bedrooms == n_bedrooms\n",
    "    # Generate the estimates\n",
    "    estimate, se, moe = get_estimates_and_errors(df_h[df_filter], 'WGTP')\n",
    "    # Display the results\n",
    "    print('Estimate of '+str(n_bedrooms)+' units: '+str(estimate)+' +/- '+str(moe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### People by Number of Bedrooms\n",
    "So far we have been evaluating the data in isolation.  Let's see what happens when we put them together.  We want the count of people by number of bedrooms.  According to data ferrett, in NYS this is how it breaks out:\n",
    "\n",
    "    0 = 424,789\t\n",
    "    1 = 2,374,676\n",
    "    2 = 4,652,957\n",
    "    3 = 6,872,722\n",
    "    4 = 3,445,711\n",
    "    5 = 941,339\n",
    "    6 = 51,239\n",
    "    7 = 0\n",
    "    8 = 252,461\n",
    "    9 = 78,025\n",
    "    N/A (GQ) = 579,255\n",
    "    \n",
    "Let's see what happens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate for 1 Bedroom: 2374676 +/- 18148\n",
      "Estimate for 2 Bedrooms: 4652957 +/- 29125\n",
      "Estimate for 3 Bedrooms: 6872722 +/- 31345\n",
      "Estimate for 4 Bedrooms: 3445711 +/- 25370\n",
      "Estimate for 5 Bedrooms: 941339 +/- 17266\n",
      "Estimate for 6+ Bedrooms: 381725 +/- 12280\n",
      "Estimate for N/A (GQ): 579255 +/- 0\n",
      "Estimate for Studio: 424789 +/- 9586\n"
     ]
    }
   ],
   "source": [
    "# To free up some memory we need to subset the housing data\n",
    "h_vars = ['SERIALNO', 'n_bedrooms', 'VALP', 'ADJINC', 'TEN', \n",
    "          'WGTP', 'WGTP1', 'WGTP2', 'WGTP3', 'WGTP4', 'WGTP5', \n",
    "          'WGTP6', 'WGTP7', 'WGTP8', 'WGTP9', 'WGTP10', 'WGTP11', \n",
    "          'WGTP12', 'WGTP13', 'WGTP14', 'WGTP15', 'WGTP16', 'WGTP17', \n",
    "          'WGTP18', 'WGTP19', 'WGTP20', 'WGTP21', 'WGTP22', 'WGTP23', \n",
    "          'WGTP24', 'WGTP25', 'WGTP26', 'WGTP27', 'WGTP28', 'WGTP29', \n",
    "          'WGTP30', 'WGTP31', 'WGTP32', 'WGTP33', 'WGTP34', 'WGTP35', \n",
    "          'WGTP36', 'WGTP37', 'WGTP38', 'WGTP39', 'WGTP40', 'WGTP41', \n",
    "          'WGTP42', 'WGTP43', 'WGTP44', 'WGTP45', 'WGTP46', 'WGTP47', \n",
    "          'WGTP48', 'WGTP49', 'WGTP50', 'WGTP51', 'WGTP52', 'WGTP53', \n",
    "          'WGTP54', 'WGTP55', 'WGTP56', 'WGTP57', 'WGTP58', 'WGTP59', \n",
    "          'WGTP60', 'WGTP61', 'WGTP62', 'WGTP63', 'WGTP64', 'WGTP65', \n",
    "          'WGTP66', 'WGTP67', 'WGTP68', 'WGTP69', 'WGTP70', 'WGTP71', \n",
    "          'WGTP72', 'WGTP73', 'WGTP74', 'WGTP75', 'WGTP76', 'WGTP77', \n",
    "          'WGTP78', 'WGTP79', 'WGTP80']\n",
    "\n",
    "# Now we can join the two data frames together (INNER JOIN in SQL speak)\n",
    "df = pd.merge(df_h[h_vars], df_p, on='SERIALNO')\n",
    "\n",
    "# Cross your fingers and hope this works\n",
    "ns_bedrooms = df.n_bedrooms.unique()\n",
    "ns_bedrooms.sort()\n",
    "for n_bedrooms in ns_bedrooms:\n",
    "    df_filter = df.n_bedrooms == n_bedrooms\n",
    "    estimate, se, moe = get_estimates_and_errors(df[df_filter], 'PWGTP')\n",
    "    print('Estimate for '+str(n_bedrooms)+': '+str(estimate)+' +/- '+str(moe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have verified the methodology we can proceed with the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syosset Park Analysis \n",
    "\n",
    "## Variable Recoding\n",
    "\n",
    "We will estimate the number of people and school age children resulting from the housing development.  Our model will use two different data points.  One is the number of bedrooms and the other is the value of the housing.  We have the number of bedrooms recoded but we don't have the home value.\n",
    "\n",
    "Since the PUMS data spans a 5 year period it must undergo an inflation adjustement to bring it into 2015 dollars.  This will be preformed then the data will be recoded based on the 2015 dollar value of the property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The recode home value function\n",
    "def recode_inf_adj_val(val):\n",
    "    \"\"\"Recodes the dollar value into one of our categories\n",
    "\n",
    "    Args:\n",
    "        val (mixed): the value to be recoded.\n",
    "    Returns:\n",
    "        recoded_val (str): The new categorical variable.\n",
    "    \"\"\"\n",
    "    if np.isnan(val):   return('N/A (GQ)')\n",
    "    elif val < 100000:  return('Less than $100,000')\n",
    "    elif val < 200000:  return(\"$100,000's\")\n",
    "    elif val < 300000:  return(\"$200,000's\")\n",
    "    elif val < 400000:  return(\"$300,000's\")\n",
    "    elif val < 500000:  return(\"$400,000's\")\n",
    "    elif val < 600000:  return(\"$500,000's\")\n",
    "    elif val < 700000:  return(\"$600,000's\")\n",
    "    elif val < 800000:  return(\"$700,000's\")\n",
    "    elif val < 900000:  return(\"$800,000's\")\n",
    "    elif val < 1000000: return(\"$900,000's\")\n",
    "    else: return('$1,000,000 or Higher')\n",
    "\n",
    "# This is the inflation adjustment\n",
    "df['inf_adj_val'] = df.VALP * (df.ADJINC/1000000)\n",
    "\n",
    "# Now we can recode the home value\n",
    "df['home_val'] = df.inf_adj_val.apply(recode_inf_adj_val, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last variable that will need to be recoded is a flag for if the individual is a school age child or not.  We are defining school age as 5-17 years old."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The recode home value function\n",
    "def recode_AGEP(val):\n",
    "    \"\"\"Recodes the dollar value into one of our categories\n",
    "\n",
    "    Args:\n",
    "        val (mixed): the value to be recoded.\n",
    "    Returns:\n",
    "        recoded_val (str): The new categorical variable.\n",
    "    \"\"\"\n",
    "    if np.isnan(val):   return('N/A')\n",
    "    elif val > 4 and val < 18:  return('Yes')\n",
    "    else: return('No')\n",
    "\n",
    "# Now we can recode the home value\n",
    "df['school_age_child'] = df.AGEP.apply(recode_AGEP, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtering the Data\n",
    "\n",
    "We only are interested in a subset of our data frame.  \n",
    "\n",
    "### Geography\n",
    "\n",
    "Geographically we are only looking at the Syosset School District."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following PUMAS are what we want to include\n",
    "valid_PUMA00 = ['04202', '04203']\n",
    "valid_PUMA10 = ['03202', '03203']\n",
    "\n",
    "# Create the geography filter\n",
    "geo_filter = np.logical_or(df['PUMA00'].isin(valid_PUMA00), df['PUMA10'].isin(valid_PUMA10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tenure\n",
    "\n",
    "Since the development will be condos we are only interested in the population living in owner-occupied housing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tenure_filter = np.logical_or(df['TEN']==1, df['TEN'] == 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Filter\n",
    "We can bring the two together for our data frame filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(981671, 173)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter = np.logical_and(geo_filter, tenure_filter)\n",
    "\n",
    "# Get the row and column count before filtering\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10598, 173)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter the data\n",
    "df = df[df_filter]\n",
    "\n",
    "# Get the row and column count after filtering\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total Housing Units by Type Estimates\n",
    "In order to get the count of housing units by the number of bed rooms and home value we will need to apply the same filters and recoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create the geography filter\n",
    "geo_filter = np.logical_or(df_h['PUMA00'].isin(valid_PUMA00), df_h['PUMA10'].isin(valid_PUMA10))\n",
    "# Create the tenure filter\n",
    "tenure_filter = np.logical_or(df_h['TEN']==1, df_h['TEN'] == 2)\n",
    "# Combine the two\n",
    "df_filter = np.logical_and(geo_filter, tenure_filter)\n",
    "# Filter the data\n",
    "df_h = df_h[df_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Number of Bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate for 1 Bedroom: 1152 +/- 303\n",
      "Estimate for 2 Bedrooms: 5303 +/- 477\n",
      "Estimate for 3 Bedrooms: 25801 +/- 944\n",
      "Estimate for 4 Bedrooms: 19019 +/- 972\n",
      "Estimate for 5 Bedrooms: 6570 +/- 664\n",
      "Estimate for 6+ Bedrooms: 1855 +/- 320\n",
      "Estimate for Studio: 28 +/- 34\n"
     ]
    }
   ],
   "source": [
    "ns_bedrooms = df_h.n_bedrooms.unique()\n",
    "ns_bedrooms.sort()\n",
    "for n_bedrooms in ns_bedrooms:\n",
    "    df_filter = df_h.n_bedrooms == n_bedrooms\n",
    "    estimate, se, moe = get_estimates_and_errors(df_h[df_filter], 'WGTP')\n",
    "    print('Estimate for '+str(n_bedrooms)+': '+str(estimate)+' +/- '+str(moe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Home Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate for $1,000,000 or Higher: 7773 +/- 501\n",
      "Estimate for $100,000's: 1224 +/- 279\n",
      "Estimate for $200,000's: 1968 +/- 332\n",
      "Estimate for $300,000's: 9525 +/- 667\n",
      "Estimate for $400,000's: 13724 +/- 859\n",
      "Estimate for $500,000's: 9111 +/- 632\n",
      "Estimate for $600,000's: 6879 +/- 509\n",
      "Estimate for $700,000's: 3529 +/- 455\n",
      "Estimate for $800,000's: 2533 +/- 374\n",
      "Estimate for $900,000's: 1728 +/- 268\n",
      "Estimate for Less than $100,000: 1734 +/- 305\n"
     ]
    }
   ],
   "source": [
    "# This is the inflation adjustment\n",
    "df_h['inf_adj_val'] = df_h.VALP * (df_h.ADJINC/1000000)\n",
    "\n",
    "# Now we can recode the home value\n",
    "df_h['home_val'] = df_h.inf_adj_val.apply(recode_inf_adj_val, 0)\n",
    "\n",
    "home_vals = df_h.home_val.unique()\n",
    "home_vals.sort()\n",
    "for home_val in home_vals:\n",
    "    df_filter = df_h.home_val == home_val\n",
    "    estimate, se, moe = get_estimates_and_errors(df_h[df_filter], 'WGTP')\n",
    "    print('Estimate for '+str(home_val)+': '+str(estimate)+' +/- '+str(moe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total People by Housing Type Estimates\n",
    "Now we will repeat the process on our merged data\n",
    "\n",
    "### By Number of Bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate for 1 Bedroom: 1553 +/- 407\n",
      "Estimate for 2 Bedrooms: 9912 +/- 958\n",
      "Estimate for 3 Bedrooms: 73130 +/- 2966\n",
      "Estimate for 4 Bedrooms: 62504 +/- 3312\n",
      "Estimate for 5 Bedrooms: 23320 +/- 2390\n",
      "Estimate for 6+ Bedrooms: 7548 +/- 1448\n",
      "Estimate for Studio: 42 +/- 54\n"
     ]
    }
   ],
   "source": [
    "for n_bedrooms in ns_bedrooms:\n",
    "    df_filter = df.n_bedrooms == n_bedrooms\n",
    "    estimate, se, moe = get_estimates_and_errors(df[df_filter], 'PWGTP')\n",
    "    print('Estimate for '+str(n_bedrooms)+': '+str(estimate)+' +/- '+str(moe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Home Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate for $1,000,000 or Higher: 25378 +/- 1587\n",
      "Estimate for $100,000's: 2159 +/- 613\n",
      "Estimate for $200,000's: 3781 +/- 745\n",
      "Estimate for $300,000's: 26001 +/- 2151\n",
      "Estimate for $400,000's: 41063 +/- 3159\n",
      "Estimate for $500,000's: 28600 +/- 2080\n",
      "Estimate for $600,000's: 21572 +/- 2014\n",
      "Estimate for $700,000's: 11103 +/- 1656\n",
      "Estimate for $800,000's: 8442 +/- 1318\n",
      "Estimate for $900,000's: 5510 +/- 1033\n",
      "Estimate for Less than $100,000: 4400 +/- 845\n"
     ]
    }
   ],
   "source": [
    "for home_val in home_vals:\n",
    "    df_filter = df.home_val == home_val\n",
    "    estimate, se, moe = get_estimates_and_errors(df[df_filter], 'PWGTP')\n",
    "    print('Estimate for '+str(home_val)+': '+str(estimate)+' +/- '+str(moe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total School Age Children by Housing Type Estimates\n",
    "Now we will repeat the process on our merged data\n",
    "\n",
    "### By Number of Bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate for 1 Bedroom: 38 +/- 49\n",
      "Estimate for 2 Bedrooms: 611 +/- 232\n",
      "Estimate for 3 Bedrooms: 11778 +/- 1004\n",
      "Estimate for 4 Bedrooms: 12293 +/- 1094\n",
      "Estimate for 5 Bedrooms: 4795 +/- 726\n",
      "Estimate for 6+ Bedrooms: 1588 +/- 422\n",
      "Estimate for Studio: 0 +/- 0\n"
     ]
    }
   ],
   "source": [
    "for n_bedrooms in ns_bedrooms:\n",
    "    df_filter = np.logical_and(df.n_bedrooms == n_bedrooms, df.school_age_child == 'Yes')\n",
    "    estimate, se, moe = get_estimates_and_errors(df[df_filter], 'PWGTP')\n",
    "    print('Estimate for '+str(n_bedrooms)+': '+str(estimate)+' +/- '+str(moe))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### By Home Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimate for $1,000,000 or Higher: 5545 +/- 658\n",
      "Estimate for $100,000's: 117 +/- 93\n",
      "Estimate for $200,000's: 196 +/- 137\n",
      "Estimate for $300,000's: 3261 +/- 629\n",
      "Estimate for $400,000's: 6784 +/- 1006\n",
      "Estimate for $500,000's: 4940 +/- 784\n",
      "Estimate for $600,000's: 4219 +/- 770\n",
      "Estimate for $700,000's: 2536 +/- 670\n",
      "Estimate for $800,000's: 1804 +/- 439\n",
      "Estimate for $900,000's: 1243 +/- 395\n",
      "Estimate for Less than $100,000: 458 +/- 282\n"
     ]
    }
   ],
   "source": [
    "for home_val in home_vals:\n",
    "    df_filter = np.logical_and(df.home_val == home_val, df.school_age_child == 'Yes')\n",
    "    estimate, se, moe = get_estimates_and_errors(df[df_filter], 'PWGTP')\n",
    "    print('Estimate for '+str(home_val)+': '+str(estimate)+' +/- '+str(moe))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
